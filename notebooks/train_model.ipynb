{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df905f1f",
   "metadata": {},
   "source": [
    "## Training setup and Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b13eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AgroWeather AI - LSTM Model Training\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping to stop training when validation loss stops improving\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0.0001):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last improvement\n",
    "            min_delta (float): Minimum change to qualify as improvement\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85416fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_data(data_dir='../../data/processed'):\n",
    "    \"\"\"\n",
    "    Load preprocessed data for training\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“‚ Loading processed data...\")\n",
    "    \n",
    "    X_train = np.load(f'{data_dir}/X_train.npy')\n",
    "    X_val = np.load(f'{data_dir}/X_val.npy')\n",
    "    X_test = np.load(f'{data_dir}/X_test.npy')\n",
    "    \n",
    "    y_train = np.load(f'{data_dir}/y_train.npy')\n",
    "    y_val = np.load(f'{data_dir}/y_val.npy')\n",
    "    y_test = np.load(f'{data_dir}/y_test.npy')\n",
    "    \n",
    "    # Load metadata\n",
    "    with open(f'{data_dir}/metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    print(f\"âœ… Data loaded successfully!\")\n",
    "    print(f\"   Training samples: {len(X_train):,}\")\n",
    "    print(f\"   Validation samples: {len(X_val):,}\")\n",
    "    print(f\"   Test samples: {len(X_test):,}\")\n",
    "    print(f\"   Features: {metadata['n_features']}\")\n",
    "    print(f\"   Sequence length: {metadata['sequence_length']} days\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66f04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(X_train, X_val, y_train, y_val, batch_size=32):\n",
    "    \"\"\"\n",
    "    Create PyTorch DataLoaders for batch training\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ”„ Creating DataLoaders (batch_size={batch_size})...\")\n",
    "    \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train)\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "    y_val_tensor = torch.FloatTensor(y_val)\n",
    "    \n",
    "    # Create TensorDatasets\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,  # Shuffle training data each epoch\n",
    "        drop_last=True  # Drop last incomplete batch\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # Don't shuffle validation data\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… DataLoaders created!\")\n",
    "    print(f\"   Training batches: {len(train_loader)}\")\n",
    "    print(f\"   Validation batches: {len(val_loader)}\")\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f4bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \n",
    "    Returns:\n",
    "        average training loss for this epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        # Move data to device (GPU/CPU)\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # Zero the gradients (clear from previous iteration)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass (make predictions)\n",
    "        predictions = model(X_batch)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        \n",
    "        # Backward pass (calculate gradients)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping (prevent exploding gradients)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    # Return average loss for this epoch\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate model on validation set\n",
    "    \n",
    "    Returns:\n",
    "        average validation loss\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():  # Don't calculate gradients (saves memory)\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    avg_loss = val_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                num_epochs=100, device='cpu', early_stopping_patience=15):\n",
    "    \"\"\"\n",
    "    Complete training loop with early stopping\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸŽ“ Starting training...\")\n",
    "    print(f\"   Device: {device}\")\n",
    "    print(f\"   Epochs: {num_epochs}\")\n",
    "    print(f\"   Early stopping patience: {early_stopping_patience}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize tracking\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'epochs': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    early_stopping = EarlyStopping(patience=early_stopping_patience)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Train one epoch\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Track history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['epochs'].append(epoch)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"âœ¨ New best model! Val Loss: {val_loss:.6f}\")\n",
    "        \n",
    "        # Print progress\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch:3d}/{num_epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.6f} | \"\n",
    "              f\"Val Loss: {val_loss:.6f} | \"\n",
    "              f\"Time: {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"\\nâ¹ï¸  Early stopping triggered at epoch {epoch}\")\n",
    "            print(f\"   No improvement for {early_stopping_patience} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Training complete\n",
    "    total_time = time.time() - start_time\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"âœ… Training completed!\")\n",
    "    print(f\"   Total time: {total_time/60:.2f} minutes\")\n",
    "    print(f\"   Best validation loss: {best_val_loss:.6f}\")\n",
    "    print(f\"   Final epoch: {epoch}/{num_epochs}\")\n",
    "    \n",
    "    # Restore best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, history, best_val_loss\n",
    "\n",
    "\n",
    "def save_model_and_history(model, history, best_val_loss, output_dir='models/saved'):\n",
    "    \"\"\"\n",
    "    Save trained model and training history\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ’¾ Saving model and training history...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save model weights\n",
    "    model_path = f'{output_dir}/rainfall_lstm_best.pth'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"   âœ… Model weights saved: {model_path}\")\n",
    "    \n",
    "    # Save complete model (architecture + weights)\n",
    "    full_model_path = f'{output_dir}/rainfall_lstm_full.pth'\n",
    "    torch.save(model, full_model_path)\n",
    "    print(f\"   âœ… Full model saved: {full_model_path}\")\n",
    "    \n",
    "    # Save training history\n",
    "    history_path = f'{output_dir}/training_history.pkl'\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "    print(f\"   âœ… Training history saved: {history_path}\")\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'total_epochs': len(history['epochs']),\n",
    "        'final_train_loss': history['train_loss'][-1],\n",
    "        'final_val_loss': history['val_loss'][-1]\n",
    "    }\n",
    "    \n",
    "    metadata_path = f'{output_dir}/training_metadata.pkl'\n",
    "    with open(metadata_path, 'wb') as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    print(f\"   âœ… Metadata saved: {metadata_path}\")\n",
    "\n",
    "\n",
    "def plot_training_history(history, output_dir='outputs'):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss curves\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“Š Creating training history plots...\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.plot(history['epochs'], history['train_loss'], label='Training Loss', linewidth=2)\n",
    "    plt.plot(history['epochs'], history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    \n",
    "    # Find best epoch\n",
    "    best_epoch = history['epochs'][np.argmin(history['val_loss'])]\n",
    "    best_val_loss = min(history['val_loss'])\n",
    "    \n",
    "    plt.axvline(x=best_epoch, color='red', linestyle='--', alpha=0.7, \n",
    "                label=f'Best Model (Epoch {best_epoch})')\n",
    "    \n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss (MSE)', fontsize=12)\n",
    "    plt.title('LSTM Training History - Rainfall Prediction', fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add text box with final metrics\n",
    "    textstr = f'Best Val Loss: {best_val_loss:.6f}\\nBest Epoch: {best_epoch}'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    plt.text(0.02, 0.98, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
    "             verticalalignment='top', bbox=props)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = f'../../{output_dir}/training_history.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   âœ… Training plot saved: {plot_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3a5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_model import create_model\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main training pipeline\n",
    "    \"\"\"\n",
    "    print(\"ðŸŒ¦ï¸  AgroWeather AI - LSTM Model Training\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Configuration\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_EPOCHS = 100\n",
    "    LEARNING_RATE = 0.001\n",
    "    EARLY_STOPPING_PATIENCE = 15\n",
    "    \n",
    "    # Check for GPU\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if device == 'cuda':\n",
    "        print(f\"ðŸš€ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"ðŸ’» Using CPU (training will be slower)\")\n",
    "    \n",
    "    # Step 1: Load data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, metadata = load_processed_data()\n",
    "    \n",
    "    # Step 2: Create dataloaders\n",
    "    train_loader, val_loader = create_dataloaders(X_train, X_val, y_train, y_val, BATCH_SIZE)\n",
    "    \n",
    "    # Step 3: Create model\n",
    "    print(f\"\\nðŸ§  Creating LSTM model...\")\n",
    "    model = create_model(input_size=metadata['n_features'], device=device)\n",
    "    \n",
    "    # Step 4: Define loss and optimizer\n",
    "    print(f\"\\nâš™ï¸  Setting up training components...\")\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    print(f\"   Loss function: MSELoss\")\n",
    "    print(f\"   Optimizer: Adam\")\n",
    "    print(f\"   Learning rate: {LEARNING_RATE}\")\n",
    "    \n",
    "    # Step 5: Train model\n",
    "    model, history, best_val_loss = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        device=device,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE\n",
    "    )\n",
    "    \n",
    "    # Step 6: Save model and history\n",
    "    save_model_and_history(model, history, best_val_loss)\n",
    "    \n",
    "    # Step 7: Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸŽ‰ TRAINING COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Evaluate model on test set (evaluate_model.py)\")\n",
    "    print(\"  2. Make predictions on new data\")\n",
    "    print(\"  3. Deploy model in Django API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c56503c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ¦ï¸  AgroWeather AI - LSTM Model Training\n",
      "======================================================================\n",
      "ðŸ’» Using CPU (training will be slower)\n",
      "ðŸ“‚ Loading processed data...\n",
      "âœ… Data loaded successfully!\n",
      "   Training samples: 2,908\n",
      "   Validation samples: 358\n",
      "   Test samples: 1,059\n",
      "   Features: 29\n",
      "   Sequence length: 7 days\n",
      "\n",
      "ðŸ”„ Creating DataLoaders (batch_size=32)...\n",
      "âœ… DataLoaders created!\n",
      "   Training batches: 90\n",
      "   Validation batches: 12\n",
      "\n",
      "ðŸ§  Creating LSTM model...\n",
      "\n",
      "âš™ï¸  Setting up training components...\n",
      "   Loss function: MSELoss\n",
      "   Optimizer: Adam\n",
      "   Learning rate: 0.001\n",
      "\n",
      "ðŸŽ“ Starting training...\n",
      "   Device: cpu\n",
      "   Epochs: 100\n",
      "   Early stopping patience: 15\n",
      "======================================================================\n",
      "âœ¨ New best model! Val Loss: 0.446899\n",
      "Epoch   1/100 | Train Loss: 0.951932 | Val Loss: 0.446899 | Time: 1.10s\n",
      "âœ¨ New best model! Val Loss: 0.439834\n",
      "Epoch   2/100 | Train Loss: 0.934790 | Val Loss: 0.439834 | Time: 0.83s\n",
      "Epoch   3/100 | Train Loss: 0.933492 | Val Loss: 0.442896 | Time: 0.84s\n",
      "Epoch   4/100 | Train Loss: 0.930641 | Val Loss: 0.443621 | Time: 0.80s\n",
      "Epoch   5/100 | Train Loss: 0.924883 | Val Loss: 0.440097 | Time: 0.73s\n",
      "Epoch   6/100 | Train Loss: 0.908508 | Val Loss: 0.442554 | Time: 1.24s\n",
      "âœ¨ New best model! Val Loss: 0.437019\n",
      "Epoch   7/100 | Train Loss: 0.915875 | Val Loss: 0.437019 | Time: 0.89s\n",
      "âœ¨ New best model! Val Loss: 0.432484\n",
      "Epoch   8/100 | Train Loss: 0.907314 | Val Loss: 0.432484 | Time: 1.10s\n",
      "Epoch   9/100 | Train Loss: 0.882621 | Val Loss: 0.438964 | Time: 0.77s\n",
      "âœ¨ New best model! Val Loss: 0.426323\n",
      "Epoch  10/100 | Train Loss: 0.811364 | Val Loss: 0.426323 | Time: 0.74s\n",
      "Epoch  11/100 | Train Loss: 0.873785 | Val Loss: 0.443511 | Time: 0.79s\n",
      "Epoch  12/100 | Train Loss: 0.863446 | Val Loss: 0.442312 | Time: 0.80s\n",
      "Epoch  13/100 | Train Loss: 0.848975 | Val Loss: 0.473634 | Time: 0.84s\n",
      "Epoch  14/100 | Train Loss: 0.843582 | Val Loss: 0.490965 | Time: 0.85s\n",
      "Epoch  15/100 | Train Loss: 0.797210 | Val Loss: 0.485591 | Time: 0.88s\n",
      "Epoch  16/100 | Train Loss: 0.783568 | Val Loss: 0.457793 | Time: 1.11s\n",
      "Epoch  17/100 | Train Loss: 0.737721 | Val Loss: 0.548061 | Time: 0.94s\n",
      "Epoch  18/100 | Train Loss: 0.716256 | Val Loss: 0.555670 | Time: 0.88s\n",
      "Epoch  19/100 | Train Loss: 0.653798 | Val Loss: 0.547934 | Time: 0.79s\n",
      "Epoch  20/100 | Train Loss: 0.643496 | Val Loss: 0.635798 | Time: 0.71s\n",
      "Epoch  21/100 | Train Loss: 0.592069 | Val Loss: 0.732552 | Time: 0.68s\n",
      "Epoch  22/100 | Train Loss: 0.526627 | Val Loss: 0.504330 | Time: 0.64s\n",
      "Epoch  23/100 | Train Loss: 0.528209 | Val Loss: 0.551126 | Time: 0.64s\n",
      "Epoch  24/100 | Train Loss: 0.516718 | Val Loss: 0.547449 | Time: 0.67s\n",
      "Epoch  25/100 | Train Loss: 0.446024 | Val Loss: 0.690090 | Time: 0.83s\n",
      "\n",
      "â¹ï¸  Early stopping triggered at epoch 25\n",
      "   No improvement for 15 epochs\n",
      "\n",
      "======================================================================\n",
      "âœ… Training completed!\n",
      "   Total time: 0.35 minutes\n",
      "   Best validation loss: 0.426323\n",
      "   Final epoch: 25/100\n",
      "\n",
      "ðŸ’¾ Saving model and training history...\n",
      "   âœ… Model weights saved: models/saved/rainfall_lstm_best.pth\n",
      "   âœ… Full model saved: models/saved/rainfall_lstm_full.pth\n",
      "   âœ… Training history saved: models/saved/training_history.pkl\n",
      "   âœ… Metadata saved: models/saved/training_metadata.pkl\n",
      "\n",
      "ðŸ“Š Creating training history plots...\n",
      "   âœ… Training plot saved: ../../outputs/training_history.png\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ TRAINING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Evaluate model on test set (evaluate_model.py)\n",
      "  2. Make predictions on new data\n",
      "  3. Deploy model in Django API\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
